### DATA PREPROCESSING

With this first commit I would like to begin a series of articles regarding data preprocessing because 
I see it as a fundamental step for later dealing or apply with any algorithm to extract any conclusion from them. I hope you find this articles useful.

But firstly I would like to name a few buzz words regarding what I would like to write about: Data preparation, cleaning, pre-processing, cleansing, wrangling... These words refer to the same topic, which is a set of steps or activities to pre- model data.

As an example, we can show two definitions of the Wikipedia to grasp an idea of what I wrote about above
 
 - [Data cleansing](https://en.wikipedia.org/wiki/Data_cleansing) Data cleansing or data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.[1] Data cleansing may be performed interactively with data wrangling tools, or as batch processing through scripting.
 
 - [Data wrangling](https://en.wikipedia.org/wiki/Data_wrangling), sometimes referred to as data munging, is the process of transforming and mapping data from one "raw" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. A data wrangler is a person who performs these transformation operations. This may include further munging, data visualization, data aggregation, training a statistical model, as well as many other potential uses. Data munging as a process typically follows a set of general steps which begin with extracting the data in a raw form from the data source, "munging" the raw data using algorithms (e.g. sorting) or parsing the data into predefined data structures, and finally depositing the resulting content into a data sink for storage and future use
